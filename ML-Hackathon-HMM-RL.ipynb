{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13593116,"sourceType":"datasetVersion","datasetId":8636677}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hackman Hackathon\n_____________________________________________________________________________________________________________________\n\n### \"The Oracle\": Using HMM with a trigraph and a dropoff (fallback) feature to a bigraph and unigraph analysis. \n### \"The Brains\": A simple Greedy RL agent that picks the letter with the highest probability i.e, the letter which reduces the solution space the most. \n_____________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"## Importing the required Libraries, Loading the corpus and test datasets","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport collections\nimport os \n\nALPHABET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\nCHAR_TO_INDEX = {char: i for i, char in enumerate(ALPHABET)}\nINDEX_TO_CHAR = {i: char for i, char in enumerate(ALPHABET)}\n\nprint(\"Libraries imported and alphabet defined.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-03T10:19:24.892669Z","iopub.execute_input":"2025-11-03T10:19:24.893220Z","iopub.status.idle":"2025-11-03T10:19:24.897868Z","shell.execute_reply.started":"2025-11-03T10:19:24.893199Z","shell.execute_reply":"2025-11-03T10:19:24.897309Z"}},"outputs":[{"name":"stdout","text":"Libraries imported and alphabet defined.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\nKAGGLE_CORPUS_PATH = \"/kaggle/input/corpus2/corpus.txt\"\n\ndef load_corpus(filename=KAGGLE_CORPUS_PATH):\n    \"\"\"\n    Reads the corpus file from the specified Kaggle path\n    and groups words by length.\n    \"\"\"\n    words_by_length = collections.defaultdict(list)\n    \n    if not os.path.exists(filename):\n        print(f\"--- ERROR ---\")\n        print(f\"File not found at: {filename}\")\n        print(\"Please verify the 'corpus' folder name and 'corpus.txt' file name in your Kaggle input.\")\n        \n        # Helper to debug: list contents of the input directory\n        print(\"\\nListing contents of /kaggle/input/ ...\")\n        try:\n            input_dirs = os.listdir(\"/kaggle/input\")\n            print(f\"Found: {input_dirs}\")\n            \n            # If the 'corpus' directory exists, list its contents\n            if \"corpus\" in input_dirs:\n                print(\"\\nListing contents of /kaggle/input/corpus/ ...\")\n                print(os.listdir(\"/kaggle/input/corpus\"))\n                \n        except FileNotFoundError:\n            print(\"Could not find /kaggle/input/ directory.\")\n        except Exception as e:\n            print(f\"An error occurred while listing directories: {e}\")\n        return None\n\n    # File exists, proceed to load\n    try:\n        with open(filename, 'r') as f:\n            for word in f:\n                cleaned_word = word.strip().upper()\n                if cleaned_word: # Ensure it's not an empty line\n                    words_by_length[len(cleaned_word)].append(cleaned_word)\n        \n        print(f\"Corpus loaded successfully from {filename}.\")\n        print(\"\\nWord counts by length:\")\n        for length in sorted(words_by_length.keys()):\n            print(f\"  Length {length}: {len(words_by_length[length])} words\")\n        return words_by_length\n        \n    except Exception as e:\n        print(f\"An error occurred while reading the file: {e}\")\n        return None\n\nwords_by_length = load_corpus()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T10:19:27.675641Z","iopub.execute_input":"2025-11-03T10:19:27.676559Z","iopub.status.idle":"2025-11-03T10:19:27.708665Z","shell.execute_reply.started":"2025-11-03T10:19:27.676533Z","shell.execute_reply":"2025-11-03T10:19:27.708087Z"}},"outputs":[{"name":"stdout","text":"Corpus loaded successfully from /kaggle/input/corpus2/corpus.txt.\n\nWord counts by length:\n  Length 1: 46 words\n  Length 2: 84 words\n  Length 3: 388 words\n  Length 4: 1169 words\n  Length 5: 2340 words\n  Length 6: 3755 words\n  Length 7: 5111 words\n  Length 8: 6348 words\n  Length 9: 6808 words\n  Length 10: 6465 words\n  Length 11: 5452 words\n  Length 12: 4292 words\n  Length 13: 3094 words\n  Length 14: 2019 words\n  Length 15: 1226 words\n  Length 16: 698 words\n  Length 17: 375 words\n  Length 18: 174 words\n  Length 19: 88 words\n  Length 20: 40 words\n  Length 21: 16 words\n  Length 22: 8 words\n  Length 23: 3 words\n  Length 24: 1 words\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"_________________________________________________________________________________________________________________________________\n## Understanding the Datasets: The following code shows that there are no words that are in common between the corpus and the testing set","metadata":{}},{"cell_type":"code","source":"import os\n\n# --- Load Corpus Words into a Set ---\nKAGGLE_CORPUS_PATH = \"/kaggle/input/corpus2/corpus.txt\"\ncorpus_words = set()\ntry:\n    with open(KAGGLE_CORPUS_PATH, 'r') as f:\n        for word in f:\n            corpus_words.add(word.strip().upper())\n    print(f\"Loaded {len(corpus_words)} unique words from corpus.txt\")\nexcept Exception as e:\n    print(f\"Error loading corpus: {e}\")\n\n# --- Load Test Words into a Set ---\nKAGGLE_TEST_SET_PATH = \"/kaggle/input/corpus2/test.txt\"\ntest_words = set()\ntry:\n    with open(KAGGLE_TEST_SET_PATH, 'r') as f:\n        for word in f:\n            test_words.add(word.strip().upper())\n    print(f\"Loaded {len(test_words)} unique words from test_set.txt\")\nexcept Exception as e:\n    print(f\"Error loading test set: {e}\")\n\n# --- Calculate and Print Overlap ---\nif test_words and corpus_words:\n    overlap = test_words.intersection(corpus_words)\n    overlap_percentage = (len(overlap) / len(test_words)) * 100\n    \n    print(\"\\n--- ðŸ“Š Diagnostic Results ---\")\n    print(f\"Total Test Words:     {len(test_words)}\")\n    print(f\"Total Corpus Words:   {len(corpus_words)}\")\n    print(f\"Words in BOTH files:  {len(overlap)}\")\n    print(f\"Overlap Percentage:   {overlap_percentage:.2f}%\")\n    \n    if overlap_percentage == 0.0:\n        print(\"\\n**CRITICAL FINDING:** Your test set has 0% overlap with your training corpus.\")\n        print(\"This means the corpus filtering logic will *never* be used during evaluation.\")\n        print(\"The score you are seeing is purely from your bigram fallback model.\")\n    elif overlap_percentage < 100.0:\n        print(f\"\\n**FINDING:** Only {overlap_percentage:.2f}% of your test words are in the corpus.\")\n        print(\"This means your filter is only working for a fraction of the games.\")\n    else:\n        print(\"\\n**FINDING:** 100% of test words are in the corpus.\")\n        print(\"This is good! It means the problem is a logic bug in Cell 4.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T09:01:58.624010Z","iopub.execute_input":"2025-11-03T09:01:58.624334Z","iopub.status.idle":"2025-11-03T09:01:58.655557Z","shell.execute_reply.started":"2025-11-03T09:01:58.624311Z","shell.execute_reply":"2025-11-03T09:01:58.654757Z"}},"outputs":[{"name":"stdout","text":"Loaded 49398 unique words from corpus.txt\nLoaded 2000 unique words from test_set.txt\n\n--- ðŸ“Š Diagnostic Results ---\nTotal Test Words:     2000\nTotal Corpus Words:   49398\nWords in BOTH files:  0\nOverlap Percentage:   0.00%\n\n**CRITICAL FINDING:** Your test set has 0% overlap with your training corpus.\nThis means the corpus filtering logic will *never* be used during evaluation.\nThe score you are seeing is purely from your bigram fallback model.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def train_hmm_models(words_by_length):\n    \"\"\"\n    Trains positional Unigram, Bigram, and Trigram models for each word length.\n    \"\"\"\n    hmm_models = {}\n    \n    for length, words in words_by_length.items():\n        if length == 0:\n            continue\n            \n        model = {}\n        \n        # --- 1. Unigram Model (Always possible for length >= 1) ---\n        unigram_counts = np.ones((length, 26))\n        for word in words:\n            try:\n                for pos, char in enumerate(word):\n                    unigram_counts[pos, CHAR_TO_INDEX[char]] += 1\n            except KeyError:\n                continue\n        model['unigram'] = unigram_counts / unigram_counts.sum(axis=1, keepdims=True)\n\n        # --- 2. Bigram Model (Only possible for length >= 2) ---\n        if length >= 2:\n            bigram_counts = np.ones((length - 1, 26, 26))\n            for word in words:\n                try:\n                    for pos in range(length - 1):\n                        prev_char_idx = CHAR_TO_INDEX[word[pos]]\n                        curr_char_idx = CHAR_TO_INDEX[word[pos + 1]]\n                        bigram_counts[pos, prev_char_idx, curr_char_idx] += 1\n                except KeyError:\n                    continue\n            model['bigram'] = bigram_counts / bigram_counts.sum(axis=2, keepdims=True)\n\n        # --- 3. Trigram Model (Only possible for length >= 3) ---\n        if length >= 3:\n            trigram_counts = np.ones((length - 2, 26, 26, 26))\n            for word in words:\n                try:\n                    for pos in range(length - 2):\n                        prev_prev_char_idx = CHAR_TO_INDEX[word[pos]]\n                        prev_char_idx = CHAR_TO_INDEX[word[pos + 1]]\n                        curr_char_idx = CHAR_TO_INDEX[word[pos + 2]]\n                        trigram_counts[pos, prev_prev_char_idx, prev_char_idx, curr_char_idx] += 1\n                except KeyError:\n                    continue\n            model['trigram'] = trigram_counts / trigram_counts.sum(axis=3, keepdims=True)\n        \n        # Store the trained models\n        hmm_models[length] = model\n        \n    print(f\"Training complete. {len(hmm_models)} (U, B, T) models trained.\")\n    return hmm_models\n\nhmm_models = train_hmm_models(words_by_length)\n\n# --- Example: Check 'TH' -> 'E' transition for 5-letter words ---\nif 5 in hmm_models:\n    t_idx = CHAR_TO_INDEX['T']\n    h_idx = CHAR_TO_INDEX['H']\n    e_idx = CHAR_TO_INDEX['E']\n    \n    # Get P(Letter_2 | Letter_0='T', Letter_1='H')\n    if 'trigram' in hmm_models[5]:\n        prob_th_e = hmm_models[5]['trigram'][0, t_idx, h_idx, e_idx]\n        print(\"\\n--- Trigram Model Sanity Check (5-letter words) ---\")\n        print(f\"  P(Letter at pos 2 = 'E' | ...pos 0 = 'T', pos 1 = 'H') = {prob_th_e:.4f}\")\n    else:\n        print(\"Trigram model for length 5 not available (this shouldn't happen).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T10:19:29.873615Z","iopub.execute_input":"2025-11-03T10:19:29.874199Z","iopub.status.idle":"2025-11-03T10:19:30.589053Z","shell.execute_reply.started":"2025-11-03T10:19:29.874177Z","shell.execute_reply":"2025-11-03T10:19:30.588263Z"}},"outputs":[{"name":"stdout","text":"Training complete. 24 (U, B, T) models trained.\n\n--- Trigram Model Sanity Check (5-letter words) ---\n  P(Letter at pos 2 = 'E' | ...pos 0 = 'T', pos 1 = 'H') = 0.0750\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Formulating the HMM (from scratch)\n\n____________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"class HMMOracle:\n    def __init__(self, models):\n        self.models = models\n        print(\"HMMOracle (Trigram w/ Backoff) initialized.\")\n\n    def _get_prob_with_backoff(self, model, pos, pattern, char_index):\n        \"\"\"\n        Gets the probability of a character at a specific position,\n        using the best available n-gram model (Trigram -> Bigram -> Unigram).\n        \"\"\"\n        \n        # --- Try Trigram ---\n        # P(char | char_at_pos-2, char_at_pos-1)\n        if pos >= 2 and pattern[pos-2] != '_' and pattern[pos-1] != '_':\n            prev_prev_idx = CHAR_TO_INDEX[pattern[pos-2]]\n            prev_idx = CHAR_TO_INDEX[pattern[pos-1]]\n            # trigram_probs[pos-2, char_{i-2}, char_{i-1}, char_i]\n            return model['trigram'][pos-2, prev_prev_idx, prev_idx, char_index]\n            \n        # --- Try Bigram ---\n        # P(char | char_at_pos-1)\n        if pos >= 1 and pattern[pos-1] != '_':\n            prev_idx = CHAR_TO_INDEX[pattern[pos-1]]\n            # bigram_probs[pos-1, char_{i-1}, char_i]\n            return model['bigram'][pos-1, prev_idx, char_index]\n            \n        # --- Fallback to Unigram ---\n        # P(char_i)\n        return model['unigram'][pos, char_index]\n        \n\n    def get_letter_probabilities(self, pattern, guessed_letters):\n        \"\"\"\n        Estimates the probability of each remaining letter appearing\n        in one of the blank spots, using trigram backoff logic.\n        \"\"\"\n        word_length = len(pattern)\n        \n        if word_length not in self.models:\n            # Fallback for models we couldn't train (e.g., length 1)\n            unguessed = [c for c in ALPHABET if c not in guessed_letters]\n            if not unguessed: return {}\n            prob = 1.0 / len(unguessed)\n            return {char: prob for char in unguessed}\n            \n        model = self.models[word_length]\n        \n        blank_indices = [i for i, char in enumerate(pattern) if char == '_']\n        unguessed_chars = [c for c in ALPHABET if c not in guessed_letters]\n        \n        if not blank_indices or not unguessed_chars:\n            return {}\n            \n        final_scores = {char: 0.0 for char in unguessed_chars}\n        \n        # 3. Iterate over each blank and score each candidate letter\n        for blank_pos in blank_indices:\n            for char in unguessed_chars:\n                char_index = CHAR_TO_INDEX[char]\n                \n                # --- P(Letter | Left_Neighbors) ---\n                # Get the probability of this char given its left context\n                left_prob = self._get_prob_with_backoff(model, blank_pos, pattern, char_index)\n                \n                # --- P(Right_Neighbors | Letter) ---\n                # Now, find how well this char \"predicts\" its right-side context\n                right_prob = 1.0\n                \n                # Check for known letter at pos+1\n                if blank_pos + 1 < word_length and pattern[blank_pos+1] != '_':\n                    next_idx = CHAR_TO_INDEX[pattern[blank_pos+1]]\n                    # P(char_at_pos+1 | char_at_pos)\n                    right_prob *= model['bigram'][blank_pos, char_index, next_idx]\n                \n                # Check for known letter at pos+2\n                if blank_pos + 2 < word_length and pattern[blank_pos+1] != '_' and pattern[blank_pos+2] != '_':\n                    next_idx = CHAR_TO_INDEX[pattern[blank_pos+1]]\n                    next_next_idx = CHAR_TO_INDEX[pattern[blank_pos+2]]\n                    # P(char_at_pos+2 | char_at_pos, char_at_pos+1)\n                    right_prob *= model['trigram'][blank_pos, char_index, next_idx, next_next_idx]\n                \n                # This score represents how well this char \"fits\" in this blank\n                prob_at_this_pos = left_prob * right_prob\n                final_scores[char] += prob_at_this_pos\n\n        # 4. Normalize scores to create a probability distribution\n        total_score = sum(final_scores.values())\n        \n        if total_score == 0.0:\n            # Fallback: No letter fits, return uniform prob\n            prob = 1.0 / len(unguessed_chars)\n            return {char: prob for char in unguessed_chars}\n            \n        normalized_probs = {\n            char: score / total_score\n            for char, score in final_scores.items()\n        }\n        \n        return normalized_probs\n\n# --- Initialize the new oracle ---\nif 'hmm_models' in locals():\n    oracle = HMMOracle(hmm_models)\nelse:\n    print(\"Error: 'hmm_models' not initialized. Please re-run Cell 3.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T10:19:33.387459Z","iopub.execute_input":"2025-11-03T10:19:33.388012Z","iopub.status.idle":"2025-11-03T10:19:33.401410Z","shell.execute_reply.started":"2025-11-03T10:19:33.387990Z","shell.execute_reply":"2025-11-03T10:19:33.400666Z"}},"outputs":[{"name":"stdout","text":"HMMOracle (Trigram w/ Backoff) initialized.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Example:  Three words: \"S____\", \"_PPLE\", __A_I_G\"\n\n______________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"# --- Example 1: A common 5-letter word start ---\npattern1 = \"S____\"\nguessed1 = {'S'}\nprobs1 = oracle.get_letter_probabilities(pattern1, guessed1)\n\nprint(f\"--- Probs for '{pattern1}' (guessed: {guessed1}) ---\")\n# Sort by probability, descending\nfor char, prob in sorted(probs1.items(), key=lambda item: item[1], reverse=True)[:10]:\n    print(f\"  P({char}): {prob:.4f}\")\n\n\n# --- Example 2: The 'APPLE' example from the prompt ---\npattern2 = \"_PPLE\"\nguessed2 = {'P', 'L', 'E'}\nprobs2 = oracle.get_letter_probabilities(pattern2, guessed2)\n\nprint(f\"\\n--- Probs for '{pattern2}' (guessed: {guessed2}) ---\")\nfor char, prob in sorted(probs2.items(), key=lambda item: item[1], reverse=True)[:5]:\n    print(f\"  P({char}): {prob:.4f}\")\n\n    \n# --- Example 3: More complex pattern ---\npattern3 = \"__A_I_G\"\nguessed3 = {'A', 'I', 'G'}\nprobs3 = oracle.get_letter_probabilities(pattern3, guessed3)\n\nprint(f\"\\n--- Probs for '{pattern3}' (guessed: {guessed3}) ---\")\nfor char, prob in sorted(probs3.items(), key=lambda item: item[1], reverse=True)[:10]:\n    print(f\"  P({char}): {prob:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T10:19:36.862297Z","iopub.execute_input":"2025-11-03T10:19:36.862641Z","iopub.status.idle":"2025-11-03T10:19:36.870327Z","shell.execute_reply.started":"2025-11-03T10:19:36.862621Z","shell.execute_reply":"2025-11-03T10:19:36.869693Z"}},"outputs":[{"name":"stdout","text":"--- Probs for 'S____' (guessed: {'S'}) ---\n  P(E): 0.1110\n  P(A): 0.1020\n  P(T): 0.0788\n  P(I): 0.0689\n  P(O): 0.0680\n  P(N): 0.0642\n  P(L): 0.0616\n  P(R): 0.0597\n  P(H): 0.0460\n  P(C): 0.0452\n\n--- Probs for '_PPLE' (guessed: {'P', 'L', 'E'}) ---\n  P(S): 0.3186\n  P(U): 0.1231\n  P(A): 0.1220\n  P(M): 0.0451\n  P(H): 0.0417\n\n--- Probs for '__A_I_G' (guessed: {'I', 'A', 'G'}) ---\n  P(N): 0.1331\n  P(S): 0.0988\n  P(C): 0.0816\n  P(P): 0.0694\n  P(R): 0.0683\n  P(T): 0.0681\n  P(B): 0.0622\n  P(L): 0.0589\n  P(M): 0.0515\n  P(D): 0.0482\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport random\n\nKAGGLE_TEST_SET_PATH = \"/kaggle/input/corpus2/test.txt\"\n\ndef load_test_set(filename=KAGGLE_TEST_SET_PATH):\n    \"\"\"\n    Loads the test set words from the specified Kaggle path.\n    \"\"\"\n    # Check if the file exists\n    if not os.path.exists(filename):\n        print(f\"--- ERROR ---\")\n        print(f\"Test set file not found at: {filename}\")\n        print(\"Please verify the 'corpus2' folder name and the test set file name.\")\n        \n        # Helper to debug: list contents of the directory\n        print(f\"\\nListing contents of {os.path.dirname(filename)} ...\")\n        try:\n            print(os.listdir(os.path.dirname(filename)))\n        except Exception as e:\n            print(f\"Could not list directory: {e}\")\n        return None\n\n    # File exists, proceed to load\n    try:\n        with open(filename, 'r') as f:\n            test_words = [word.strip().upper() for word in f if word.strip()]\n        \n        print(f\"Test set loaded successfully from {filename}.\")\n        print(f\"Found {len(test_words)} test words.\")\n        return test_words\n        \n    except Exception as e:\n        print(f\"An error occurred while reading the test file: {e}\")\n        return None\n\ndef play_game(secret_word, oracle, max_lives=6):\n    \"\"\"\n    Simulates a single game of Hangman using a greedy agent\n    that trusts the HMMOracle.\n    \"\"\"\n    word_length = len(secret_word)\n    pattern = \"_\" * word_length\n    guessed_letters = set()\n    \n    wrong_guesses = 0\n    repeated_guesses = 0 # Will be 0 with our current oracle\n    lives = max_lives\n    \n    while lives > 0 and \"_\" in pattern:\n        probs = oracle.get_letter_probabilities(pattern, guessed_letters)\n        \n        if not probs:\n            break # Game is lost\n            \n        # 3. Greedy Agent: Pick the best letter\n        guess = max(probs, key=probs.get)\n        \n        \n        guessed_letters.add(guess)\n        \n        if guess in secret_word:\n            # Correct guess: update pattern\n            new_pattern = list(pattern)\n            for i in range(word_length):\n                if secret_word[i] == guess:\n                    new_pattern[i] = guess\n            pattern = \"\".join(new_pattern)\n        else:\n            # Wrong guess\n            wrong_guesses += 1\n            lives -= 1\n            \n    # 5. Return game results\n    game_won = \"_\" not in pattern\n    return game_won, wrong_guesses, repeated_guesses\n\n# --- Main Evaluation Loop ---\n\n# Load the test words\ntest_words = load_test_set()\n\nif test_words and oracle:\n    NUM_GAMES = 2000 # As specified in the PDF \n    MAX_LIVES = 6      # As specified in the PDF \n    \n    total_games_won = 0\n    total_wrong_guesses = 0\n    total_repeated_guesses = 0\n    \n    print(f\"\\n--- Starting Evaluation: Playing {NUM_GAMES} games ---\")\n\n    if not test_words:\n        print(\"Cannot run evaluation: test_words list is empty.\")\n    else:\n        test_set_size = len(test_words)\n        \n        for i in range(NUM_GAMES):\n           \n            secret_word = random.choice(test_words)\n            \n            if len(secret_word) not in oracle.models:\n                # print(f\"Skipping word '{secret_word}': No model for length {len(secret_word)}\")\n                continue\n\n            won, wrongs, repeats = play_game(secret_word, oracle, MAX_LIVES)\n            \n            if won:\n                total_games_won += 1\n            total_wrong_guesses += wrongs\n            total_repeated_guesses += repeats\n            \n            if (i + 1) % 200 == 0:\n                print(f\"  ... completed {i + 1} / {NUM_GAMES} games\")\n\n        print(\"--- Evaluation Complete ---\")\n        success_rate = total_games_won / NUM_GAMES\n        avg_wrong_guesses = total_wrong_guesses / NUM_GAMES\n        avg_repeated_guesses = total_repeated_guesses / NUM_GAMES\n        \n        # 2. Calculate Final Score using the formula \n        # Final Score = (Success Rate * 2000) - (Total Wrong Guesses * 5) - (Total Repeated Guesses * 2)\n        \n        # (Success Rate * 2000) is just total_games_won\n        score_from_wins = success_rate * 2000 \n        penalty_from_wrongs = total_wrong_guesses * 5\n        penalty_from_repeats = total_repeated_guesses * 2\n        \n        final_score = score_from_wins - penalty_from_wrongs - penalty_from_repeats\n        \n        # 3. Print Results\n        print(\"\\n--- ðŸ“Š Final Results ---\")\n        print(f\"**Final Score:** {final_score:.2f}\")\n        print(\"------------------------------\")\n        print(f\"Total Games Played:     {NUM_GAMES}\")\n        print(f\"Total Games Won:        {total_games_won} ({success_rate * 100:.2f}%)\")\n        print(\"------------------------------\")\n        print(f\"Total Wrong Guesses:    {total_wrong_guesses} (Avg: {avg_wrong_guesses:.2f} per game)\")\n        print(f\"Total Repeated Guesses: {total_repeated_guesses} (Avg: {avg_repeated_guesses:.2f} per game)\")\n        print(\"------------------------------\")\n        print(f\"Score from Wins:        + {score_from_wins:.2f}\")\n        print(f\"Penalty from Wrongs:    - {penalty_from_wrongs:.2f}\")\n        print(f\"Penalty from Repeats:   - {penalty_from_repeats:.2f}\")\n        \nelse:\n    print(\"\\nEvaluation not run. Could not load test set or oracle is not initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T10:20:02.870062Z","iopub.execute_input":"2025-11-03T10:20:02.870372Z","iopub.status.idle":"2025-11-03T10:20:05.311978Z","shell.execute_reply.started":"2025-11-03T10:20:02.870351Z","shell.execute_reply":"2025-11-03T10:20:05.311228Z"}},"outputs":[{"name":"stdout","text":"Test set loaded successfully from /kaggle/input/corpus2/test.txt.\nFound 2000 test words.\n\n--- Starting Evaluation: Playing 2000 games ---\n  ... completed 200 / 2000 games\n  ... completed 400 / 2000 games\n  ... completed 600 / 2000 games\n  ... completed 800 / 2000 games\n  ... completed 1000 / 2000 games\n  ... completed 1200 / 2000 games\n  ... completed 1400 / 2000 games\n  ... completed 1600 / 2000 games\n  ... completed 1800 / 2000 games\n  ... completed 2000 / 2000 games\n--- Evaluation Complete ---\n\n--- ðŸ“Š Final Results ---\n**Final Score:** -47859.00\n------------------------------\nTotal Games Played:     2000\nTotal Games Won:        796 (39.80%)\n------------------------------\nTotal Wrong Guesses:    9731 (Avg: 4.87 per game)\nTotal Repeated Guesses: 0 (Avg: 0.00 per game)\n------------------------------\nScore from Wins:        + 796.00\nPenalty from Wrongs:    - 48655.00\nPenalty from Repeats:   - 0.00\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Members:\n\n#### Prateek Meher K\n\n#### Kushal Kumar G\n\n#### Mahima R Shetty\n\n#### Jyotsana S\n\n______________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}